---
title: "Estimating Value-at-Risk of a Portfolio with GARCH-family ModelsS"
author: "Andrei Shelest, Zofia Bracha"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: spacelab
    highlight: tango
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo    = TRUE, 
                      cache   = TRUE,
                      message = FALSE, 
                      warning = FALSE)
options(scipen = 10)
```

```{r cache = F}
library(tidyverse)
library(xts)
library(fBasics)
library(tseries)
library(car)
library(FinTS)
library(rugarch) 
library(quantmod)
library(hash)
```

- Everywhere here significance is assumed at p=0.05, if not said otherwise.
- LB - Ljung-Box test
- LM - Lagrange multipliers test

# Components of Portfolio

For the purposes of the project, the following instruments have been used.

- Equity index: S&P500 (^SPX)
- Company stock: Dell Technologies Inc. (DELL)
- Currency pair: EUR/USD (EURUSD=X)
- Brent Crude Oil (BZ=F)
- Ethereum USD (ETH-USD)

Data is downloaded from Yahoo Finance, for the period from 2019-01-01 to 2023-12-31.

```{r}
tickers <- c("^SPX", "DELL", "EURUSD", "BZ=F", "ETH-USD")

date_from <- "2019-01-01"
date_to <- "2023-12-31"

download_data <- FALSE

if(download_data){
  for(ticker in tickers){
    if(ticker == "EURUSD") {
      next # downloaded from stooq instead, because of apparent incorrect dates in yahoo for EUR/USD
    }
    ticker_data <- getSymbols(Symbols = ticker,
             from = date_from,
             to = date_to,
             src="yahoo",
             auto.assign = FALSE)
    act_ticker <- gsub("^\\^", "", ticker)
    adj_ticker <- sprintf("%s.Adjusted", act_ticker)
    
    ticker_df <- data.frame(Date=index(ticker_data), Adjusted=ticker_data[, adj_ticker])
    names(ticker_df)[2] <- "Adjusted"

    write.csv(ticker_df, sprintf("./data/%s.csv", ticker), row.names=FALSE)
  }
}
```
```{r}
plot_quotes = function(df, quote_col, title){
  if(has_name(df, "Date"))
  {
      df_xts <- xts(df[, quote_col], order.by=df$Date)
  }
  else{
    df_xts <- xts(df[, quote_col], order.by=as.Date(rownames(df)))
  }
  plot(df_xts[,1],
     main = title,
     col = "red",
     major.ticks = "years", 
     grid.ticks.on = "years",
     grid.ticks.lty = 3,
     lwd = 2,
     cex = 0.5) 
}
```

## Quotes and Returns


```{r}
tickers_map = hash()
joined_returns = NULL

lr_label = function(ticker){
  return(sprintf("%s.r", ticker))
}


for(ticker in tickers){
  ticker_df <- read.csv(sprintf("./data/%s.csv", ticker), header=TRUE)
  ticker_df$Date <- as.Date(ticker_df$Date)
  
  r_label <- lr_label(ticker)
  
  ticker_df[[r_label]] <- diff.xts(log(ticker_df$Adjusted)) # log return
  
  tickers_map[[ticker]] <- ticker_df
  
  if(is.null(joined_returns)) {
    joined_returns <- ticker_df %>% select(Date, `r_label`)
  }
  else {
    joined_returns <- full_join(joined_returns, ticker_df %>% select(Date, `r_label`))
  }
  
}

joined_returns <- joined_returns %>% arrange(Date)
```
### S&P500

```{r}
plot_quotes(tickers_map[[tickers[1]]], "Adjusted", sprintf("%s Quotes", tickers[1]))
plot_quotes(tickers_map[[tickers[1]]], lr_label(tickers[1]), sprintf("%s differenced log returns", tickers[1]))
```

We observe huge volatility clustering around 2020 market crash and in 2022 during bearish market.

### Dell

```{r}
plot_quotes(tickers_map[[tickers[2]]], "Adjusted", sprintf("%s Quotes", tickers[2]))
plot_quotes(tickers_map[[tickers[2]]], lr_label(tickers[2]), sprintf("%s differenced log returns", tickers[2]))
```

Here the 2020 volatility cluster is more pronounced than of 2022.

### EUR/USD

```{r}
plot_quotes(tickers_map[[tickers[3]]], "Adjusted", sprintf("%s Quotes", tickers[3]))
plot_quotes(tickers_map[[tickers[3]]], lr_label(tickers[3]), sprintf("%s differenced log returns", tickers[3]))
```

For EUR/USD volatility cluster is visible for 2022.

### Brent

```{r}
plot_quotes(tickers_map[[tickers[4]]], "Adjusted", sprintf("%s Quotes", tickers[4]))
plot_quotes(tickers_map[[tickers[4]]], lr_label(tickers[4]), sprintf("%s differenced log returns", tickers[4]))
```

For Brent Crude Oil volatility clustering is observed in 2020 in 2022. 

### Ethereum

```{r}
plot_quotes(tickers_map[[tickers[5]]], "Adjusted", sprintf("%s Quotes", tickers[5]))
plot_quotes(tickers_map[[tickers[5]]], lr_label(tickers[5]), sprintf("%s differenced log returns", tickers[5]))
```

Not only does Ethereum have a volatility cluster around 2020 crash, but also it has volatility clustering in 2021, the era of meme stocks and coins. Obviously, it is even better visible on quotes chart.

## Portfolio

### Constructing Joint Log Returns

Here the important decision is whether to trade or not to trade on weekends and bank holidays. Since only Ethereum is traded all the time, we decide to trade only on working days. The alternative option is to replace all non-trading day returns with zeros, but this solution will reduce the overall variance of returns.

The list of non trading days was generated by ChatGPT-4o prompt "I need a list of weekend days and bank holidays for US since 2015 till 2025 in CSV file, column named Date, dates in format YYYY-mm-dd".

```{r}
non_trading_days <- read.csv("./data/non_trading_days.csv", header=TRUE)

joined_returns <- joined_returns %>% filter(! Date %in% non_trading_days$Date) %>% slice(-1)
print(sprintf("NAs left: %i", sum(is.na(joined_returns))))
```

The rest of the possible missing returns we are replacing with zeros.

```{r}
joined_returns <- joined_returns %>% replace(is.na(.), 0)
```

Now let's calculate the log-return of portfolio ($w_i=w=1/N$, $R$ stands for arithmetic return, $r$ - for logarithmic return).

$$
ln \dfrac{\Pi_{t+1}}{\Pi_{t}} = ln\dfrac{\sum_{i=1}^{N}S_{i,t+1}}{\Pi_t}=ln\dfrac{1/N\,\sum_{i=1}^{N}\Pi_{t}R_{i,t+1}}{\Pi_t} = ln \dfrac{1}{N}\sum_{i=1}^{N}R_{i,t+1} = ln \dfrac{1}{N}\sum_{i=1}^{N}e^{r_{i,t+1}}
$$

```{r}
ret_sum <- numeric(length(joined_returns))

for(ticker in tickers){
  ret_sum <- ret_sum + exp(joined_returns[, lr_label(ticker)])
}

joined_returns$r <- log(1/length(tickers) * ret_sum)
```

```{r}
head(joined_returns, n=10)
```
```{r}
tail(joined_returns, n=10)
```

### Plots of the log-returns.
```{r}
plot_quotes(joined_returns, "r", "Portfolio differenced log returns")
```

There is a clear volatility cluster at the beginning of 2020, as well as smaller clusters in the middle of 2021 and 2022.

### ACF plots for log returns and square log returns.

```{r}
plot_acf = function(values, max_lim, title){
  acf(values, lag.max = 36, na.action = na.pass,
    ylim = c(-0.2, max_lim), col = "darkblue", lwd = 4,
    main = title)
}
```

```{r}
plot_acf(joined_returns$r, 0.2, "ACF of portfolio log-returns")
plot_acf(joined_returns$r^2, 0.4, "ACF of portfolio squared log-returns")
```

Observations:

- There are a couple of lags for plain log-returns.
- On the other hand, there are significant ACF values for lags for squared log-returns, hence we can assume the presence of serial autocorrelation.

## Formal Testing for ARCH effects

### Heteroscedasticity of Residuals

```{r}
ArchTest(joined_returns$r, lags=10)
```
LM test strongly rejects null hypothesis of homoscedasticity of log-returns and no autocorrelation of squared log-returns.

```{r}
Box.test(resid(lm(joined_returns$r ~ 1)), type = "Ljung-Box", lag = 10)
```
```{r}
Box.test(resid(lm(joined_returns$r^2 ~ 1)), type = "Ljung-Box", lag = 10)
```

Ljung-Box test also strongly rejects the hypothesis of no autocorrelation both in simple and squared log-returns.

### Leptokurtosis

```{r}
jarque.bera.test(joined_returns$r)
```

Based on Jarque-Bera test and its very small p-value, we strongly reject hypothesis of log-returns following normal distribution.

```{r}
basicStats(joined_returns$r)
```

The distribution of log-returns is left-skewed and has high kurtosis.

```{r}
hist(joined_returns$r, prob = TRUE, breaks = 50)
curve(dnorm(x, mean = mean(joined_returns$r), sd  = sd(joined_returns$r)),
            col = "darkblue", lwd = 3, add = TRUE)
```

We see more pronounced left tail and high kurtosis.

The overall conclusion is that there are ARCH effects present in the log-returns of the portfolio.

# Estimating GARCH models

```{r}
insample_r <- joined_returns %>% filter(Date < as.Date('2023-01-01'))
```

```{r}
fit_garch = function(returns, arma_p, arma_q, arch_q, garch_p){
  spec <- ugarchspec(
    variance.model = list(model = "sGARCH",
                          garchOrder = c(arch_q, garch_p)),
    mean.model = list(armaOrder = c(arma_p, arma_q), include.mean = T),
    distribution.model = "norm")
  model <- ugarchfit(spec=spec, data=returns)
  return(model)
}

```

### ARMA(0,0)-GARCH(1,1)

Let's begin with the simplest option of a constant mean equation and ARCH and GARCH orders of 1.
```{r}
plot_std_residuals = function(fit_model){
  plot(fit_model, which=10)
}
plot_std_sq_residuals = function(fit_model){
  plot(fit_model, which=11)
}
plot_conditional_sd = function(fit_model){
  plot(fit_model, which=3)
}
plot_news_impact_curve = function(fit_model) {
  plot(fit_model, which=12)
}
plot_r_std_density = function(fit_model){
  std_residuals = (fit_model@fit$residuals - mean(fit_model@fit$residuals)) / fit_model@fit$sigma

  hist(std_residuals, prob=TRUE, breaks=40)
  curve(dnorm(x, mean = mean(std_residuals), sd  = sd(std_residuals)),
            col = "darkblue", lwd = 3, add = TRUE)
}

```
```{r}
arma00garch11 <- fit_garch(insample_r$r, 0, 0, 1, 1)
arma00garch11
```

```{r}
plot_std_residuals(arma00garch11)
plot_std_sq_residuals(arma00garch11)
plot_conditional_sd(arma00garch11)
```

#### Comment

- All the estimates or parameters are significant. 
- ACF of standardized residuals shows almost no autocorrelation
- ACF of squared standardized residuals shows significant third lag.
- Both Ljung-Box test for standardized squared residuals and LM tests say that we reject null-hypothesis of no autocorrelation of said residuals, hence the model is not adequate.

### ARMA(0,0)-GARCH(2,1)

```{r}
arma00garch21 <- fit_garch(insample_r$r, 0, 0, 2, 1)
arma00garch21
```

```{r}
plot_std_residuals(arma00garch21)
plot_std_sq_residuals(arma00garch21)
plot_conditional_sd(arma00garch21)
```

#### Comment

- ARCH(1) and ARCH(2) parameters are insignificant. 
- ACF of standardized residuals shows almost no significant autocorrelation.
- ACF of squared standardized residuals shows significant third lag. It is smaller than in ARCH(0,0)-GARCH(1,1).
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals.


### ARMA(0,0)-GARCH(1,2)

```{r}
arma00garch12 <- fit_garch(insample_r$r, 0, 0, 1, 2)
arma00garch12
```
```{r}
plot_std_residuals(arma00garch12)
plot_std_sq_residuals(arma00garch12)
plot_conditional_sd(arma00garch12)
```

#### Comment

- GARCH(2) is not significant and estimated to be zero. 
- ACF of standardized residuals shows almost no autocorrelation.
- ACF of squared standardized residuals shows significant third lag.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals (except for maybe LB 8th lag, but LM test shows no autocorrelation)


### ARMA(0,0)-GARCH(2,2)

```{r}
arma00garch22 <- fit_garch(insample_r$r, 0, 0, 2, 2)
arma00garch22
```
```{r}
plot_std_residuals(arma00garch22)
plot_std_sq_residuals(arma00garch22)
plot_conditional_sd(arma00garch22)
```

#### Comment

- ARCH(1), ARCH(2) and GARCH(2) parameters are not significant. GARCH(2) is close to zero. 
- ACF of standardized residuals shows almost no autocorrelation.
- ACF of squared standardized residuals shows significant third lag.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals.


### ARMA(0,0)-GARCH(3,3)

```{r}
arma00garch33 <- fit_garch(insample_r$r, 0, 0, 3, 3)
arma00garch33
```

```{r}
plot_std_residuals(arma00garch33)
plot_std_sq_residuals(arma00garch33)
plot_conditional_sd(arma00garch33)
```

#### Comment

- ARCH(1) and GARCH(2) parameters are not significant. GARCH(2) is even estimated to be zero. 
- ACF of standardized residuals shows almost no autocorrelation.
- ACF of squared standardized residuals shows significant third lag, but its magnitude is the lowest as of now.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals.

Perhaps, now we should move to altering mean equation to see the effects.

### ARMA(7,0)-GARCH(2,1)
```{r}
arma70garch21 <- fit_garch(insample_r$r, 7, 0, 2, 1)
arma70garch21
```

```{r}
plot_std_residuals(arma70garch21)
plot_std_sq_residuals(arma70garch21)
plot_conditional_sd(arma70garch21)
```

#### Comment

- All AR lags except for the 7th are insignificant. ARCH(2) is also insignificant.
- ACF of standardized residuals shows no autocorrelation.
- ACF of squared standardized residuals shows significant third lag, as in all previous cases.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals.


### ARMA(7,7)-GARCH(2,1)
```{r}
arma77garch21 <- fit_garch(insample_r$r, 7, 7, 2, 1)
arma77garch21
```
```{r}
plot_std_residuals(arma77garch21)
plot_std_sq_residuals(arma77garch21)
plot_conditional_sd(arma77garch21)
```

#### Comment

- AR(3), AR(4), MA(3), MA(4) lags are insignificant, as well as ARCH(2). 
- ACF of standardized residuals confidently shows no autocorrelation.
- ACF of squared standardized residuals shows significant third lag, as in all previous cases.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals.


Let's try reducing amount of ARMA lags.

### ARMA(5,5)-GARCH(2,1)
```{r}
arma55garch21 <- fit_garch(insample_r$r, 5, 5, 2, 1)
arma55garch21
```
```{r}
plot_std_residuals(arma55garch21)
plot_std_sq_residuals(arma55garch21)
plot_conditional_sd(arma55garch21)
```

#### Comment

- Only ARCH(2) is insignificant. 
- ACF of standardized residuals shows one significant lag.
- ACF of squared standardized residuals shows significant third lag, as in all previous cases.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals.

Let's try adding more GARCH components.

### ARMA(5,5)-GARCH(2,2)
```{r}
arma55garch22 <- fit_garch(insample_r$r, 5, 5, 2, 2)
arma55garch22
```
```{r}
plot_std_residuals(arma55garch22)
plot_std_sq_residuals(arma55garch22)
plot_conditional_sd(arma55garch22)
```

#### Comment

- ARCH(2), GARCH(2) are insignificant. 
- ACF of standardized residuals showed significant 9th lag.
- ACF of squared standardized residuals shows significant third lag and 14th.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals. Nevertheless, ACF plots are not great, and we can conclude that this model is not that good.

### ARMA(5,5)-GARCH(3,3)
```{r}
arma55garch33 <- fit_garch(insample_r$r, 5, 5, 3, 3)
arma55garch33
```
```{r}
plot_std_residuals(arma55garch33)
plot_std_sq_residuals(arma55garch33)
plot_conditional_sd(arma55garch33)
```


#### Comment


- ARCH(1), GARCH(1), GARCH(2) are insignificant. GARCH(2) is estimated to be zero. 
- ACF of standardized residuals shows no autocorrelation.
- ACF of squared standardized residuals shows three significant lags.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals. Nevertheless, the p-values are somewhat underwhelming, and together with ACF plots we can conclude that this model is not that good.

Overall performance is not improving: more insignificant lags are appearing, and ACF plots are worsening.

### ARMA(5,5)-GARCH(3,5)
```{r}
arma55garch35 <- fit_garch(insample_r$r, 5, 5, 3, 5)
arma55garch35
```
```{r}
plot_std_residuals(arma55garch35)
plot_std_sq_residuals(arma55garch35)
plot_conditional_sd(arma55garch35)
```

#### Comment

- ARCH(1) and GARCH lags are insignificant, except for GARCH(5). GARCH(1), GARCH(3), GARCH(4) are zeros.
- ACF of standardized residuals shows no autocorrelation.
- ACF of squared standardized residuals also shows no autocorrelation.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals. 
- Model is rather complex, it isn't worth considering because of insignificant lags estimation.


## Model Selection

Since for most models LM and LB tests have not been able to reject null-hypothesis of no standardized simple/squared residuals autocorrelation, and the 3rd ACF lag for standardized squared residuals has not been removed fully by each model as well, we decide to choose among models which are the simplest and/or have the largest number of significant coefficient estimations.

These models are ARMA(0,0)-GARCH(2,1), ARMA(0,0)-GARCH(3,3) and ARMA(5,5)-GARCH(2,1).

```{r}
infocriteria(arma00garch21)
infocriteria(arma00garch33)
infocriteria(arma55garch21)
```

If we look at Akaike and Bayes criteria, ARMA(0,0)-GARCH(2,1) has the second best AIC and best BIC, ARMA(0,0)-GARCH(3,3) has the second best BIC but worst AIC, and ARMA(5,5)-GARCH(2,1) has best AIC but worst BIC. Based on this, it seems that the simpler **ARMA(0,0)-GARCH(2,1)** is better, hence we will proceed with it.

```{r}
chosen_garch = function(returns){
  return(fit_garch(returns, 0, 0, 2, 1))
}
```

## ARMA(0,0)-EGARCH(2,1)

Let's analyze the modification of the original model and see if it performs better.

```{r}
chosen_mod_garch = function(returns){
  spec <- ugarchspec(variance.model = list(model = "eGARCH", 
                                         garchOrder = c(2, 1)),
                   mean.model = list(armaOrder = c(0, 0), 
                                     include.mean = TRUE), 
                   distribution.model = "norm") 
  egarch_model <- ugarchfit(spec = spec, 
                           data = returns)
  return(egarch_model)
}
```
```{r}
arma00egarch21 <- chosen_mod_garch(insample_r$r)
arma00egarch21
```
```{r}
plot_std_residuals(arma00egarch21)
plot_std_sq_residuals(arma00egarch21)
plot_conditional_sd(arma00egarch21)
```
#### Comment

- Only gamma2 is insignificant.
- ACF of standardized residuals shows no autocorrelation.
- ACF of squared standardized residuals has only one third significant lag.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject the null. 


# Futher Diagnostics

## ARMA(0,0)-GARCH(2,1)

Let's display the statistics of the model again.

```{r}
arma00garch21
```
### Parameters Discussion

As mentioned previously, ARCH(1) and ARCH(2) are insignificant.

- Mu is an estimated mean of log-returns. It is close to zero, which is expected for log-returns.
- Omega is an intercept of conditional variance equation. It is positive and very close to zero.
- ARCH parameters are positive but small, indicating that lagged shocks somewhat influence the current conditional variance
- GARCH(1) of 0.82 shows strong influence of lagged conditional variance.




### Nyblom stability test

Regarding Nyblom stability test, we see that the joint stability statistic is large, 6.3395 > 1.47 at 5% confidence level. Hence we reject null hypothesis of joint parameter stability. Nevertheless, all individual statistics are smaller than 0.47, hence we cannot reject the null of individual parameter stability.

### Sign Bias Test

Negative Sign Bias test rejects the null of no asymmetry. It means that the model reacts strongly on negative returns. The joint effect of biases is also significant.

### Goodness-of-Fit Test

All p-values are small, suggesting that the model does not fit the data well in any grouping.

### News Impact Curve

```{r}
plot_news_impact_curve(arma00garch21)
```
The news impact curve shows that lagged shock value impacts current conditional variance equally.

### Standardized residuals

```{r}
plot_r_std_density(arma00garch21)
```
```{r}
std_residuals = (arma00garch21@fit$residuals 
                 - mean(arma00garch21@fit$residuals)) / arma00garch21@fit$sigma

print(basicStats(std_residuals))
print(jarque.bera.test(std_residuals))
```

The distribution of standardized residuals is platykurtic.

## ARMA(0,0)-EGARCH(2,1)

```{r}
arma00egarch21
```

### Parameter Discussion

- GARCH(1) is very large and highly significant. This means that previous conditional variance pretty much defines the current one.
- Gamma captures the size effect, i.e. how much the influence of the $|z_{t-j}|-E|z_{t-j}|$ component is (according to the https://cran.r-project.org/web/packages/rugarch/vignettes/Introduction_to_the_rugarch_package.pdf). Here we see that it is positive, i.e. the father standardized residuals by abs. value are from their mean, the more is the level of conditional variance.

### Nyblom Stability Test

The test fails to reject the null of both joined and individual parameter stability (all statistics are smaller than 1.9).

### Sign Bias Test

We cannot reject the null of no asymmetry. Hence, the model should behave stably with both negative and positive returns.

### Goodness-of-Fit Test

All p-values are small, suggesting that the model does not fit the data well in any grouping.

### News Impact Curve

```{r}
plot_news_impact_curve(arma00egarch21)
```
The news impact curve shows that negative lagged shock values impact current conditional variance much more than positive, which is a desirable effect for returns.

### Standardized residuals

```{r}
plot_r_std_density(arma00egarch21)
```
```{r}
std_residuals = (arma00egarch21@fit$residuals 
                 - mean(arma00egarch21@fit$residuals)) / arma00egarch21@fit$sigma

print(basicStats(std_residuals))
print(jarque.bera.test(std_residuals))
```

The distribution of standardized residuals is still platykurtic.

# Value-at-Risk

```{r}
plot_var = function(dates, returns, vars, ylims){
  if(missing(ylims))
  {
    ylims = c(-0.2, 0.1)
  }
  
  plot(dates, returns, 
   col = "red", lwd = 1, type = 'l', 
   ylim = ylims)
  abline(h = 0, lty = 2)
  lines(dates, vars, type = 'l', col = "green")
}

var_losses = function(returns, vars){
  sum(returns < vars) / length(vars)
}
```



Value-at-Risk is assumed at confidence level 1%. The empirical quantile is:

```{r}
get_var_quantile = function(returns, q_value) {
  rstd <- (returns - mean(returns))/sd(returns)
  q <-  quantile(rstd, q_value)
  return(q)
}

threshold = 0.01
var_q <- get_var_quantile(insample_r$r, threshold)
var_q
```

## In-sample

### GARCH

Calculate VAR from chosen model.

```{r}
insample_garch <- chosen_garch(insample_r$r)
vars <- var_q * insample_garch@fit$sigma
```
```{r}
plot_var(insample_r$Date, insample_r$r, vars)
```

In how many days do we breach the VaR quantile of `r threshold`?

```{r}
var_losses(insample_r$r, vars)
```
Worse than expected. Let's test with VaR 5%.

```{r}
vars <- get_var_quantile(insample_r$r, 0.05) * insample_garch@fit$sigma
plot_var(insample_r$Date, insample_r$r, vars)
var_losses(insample_r$r, vars)
```

VaR 5% breaches are in expected range.

### EGARCH

Calculate VAR from chosen EGARCH model.

```{r}
insample_egarch <- chosen_mod_garch(insample_r$r)
vars <- var_q * insample_egarch@fit$sigma
```
```{r}
plot_var(insample_r$Date, insample_r$r, vars)
```

In how many days do we breach the VaR quantile of `r threshold`?

```{r}
var_losses(insample_r$r, vars)
```
The result is acceptable. Let's test with VaR 5%.

```{r}
vars <- get_var_quantile(insample_r$r, 0.05) * insample_egarch@fit$sigma
plot_var(insample_r$Date, insample_r$r, vars)
var_losses(insample_r$r, vars)
```

VaR 5% breaches are in expected range.


## Out-of-sample

```{r}
joined_returns$obs <- 1:length(joined_returns$r)
outofsample_r <- joined_returns %>% filter(Date >= as.Date('2023-01-01'))

start <- (joined_returns %>% 
            filter(Date >= as.Date("2023-01-01")) %>% 
            filter(row_number() == 1))$obs
finish  <- (joined_returns %>% filter(row_number() == n()))$obs

forecast_rolling_var = function(q_value, garch_func) {
  vars <- rep(NA, times = finish - start + 1)
  
  for(new_idx in start:finish){
     rolling_data <- joined_returns[joined_returns$obs <= new_idx-1, ]
     q <- get_var_quantile(rolling_data$r, q_value)
     
     rolling_garch <- garch_func(rolling_data$r)
     forecast <- ugarchforecast(rolling_garch, n.ahead = 1)
     sigma_for <- forecast@forecast$sigmaFor[1, 1]
     
     vars[new_idx - start + 1]    <- q * sigma_for
  }
  
  return(vars)
}

```


### GARCH

```{r}
vars <- forecast_rolling_var(0.01, chosen_garch)
```
```{r}
plot_var(outofsample_r$Date, outofsample_r$r, vars, ylims=c(-0.05, 0.05))
var_losses(outofsample_r$r, vars)
```
There are no return values breaching VaR 1%.

### EGARCH

```{r}
vars <- forecast_rolling_var(0.01, chosen_mod_garch)
```
```{r}
plot_var(outofsample_r$Date, outofsample_r$r, vars, ylims=c(-0.05, 0.05))
var_losses(outofsample_r$r, vars)
```
There are no return values breaching VaR 1%.
