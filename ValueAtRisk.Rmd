---
title: "Estimating Value-at-Risk of a Portfolio with GARCH-family Models"
author: "Andrei Shelest, Zofia Bracha"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: spacelab
    highlight: tango
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo    = TRUE, 
                      
                      cache   = TRUE,
                      message = FALSE, 
                      warning = FALSE)
options(scipen = 10)
```

```{r cache = F}
suppressMessages({
  suppressWarnings({
    library(tidyverse)
    library(xts)
    library(fBasics)
    library(tseries)
    library(car)
    library(FinTS)
    library(rugarch) 
    library(quantmod)
    library(hash)
    library(foreach)
    library(doParallel)
  })
})
```

- Everywhere here significance is assumed at p=0.05, if not said otherwise.
- LB - Ljung-Box test
- LM - Lagrange multipliers test

# Components of Portfolio

For the purposes of the project, the following instruments have been used.

- Equity index: S&P500 (^SPX)
- Company stock: Dell Technologies Inc. (DELL)
- Currency pair: EUR/USD (EURUSD=X)
- Brent Crude Oil (BZ=F)
- Ethereum USD (ETH-USD)

Data is downloaded from Yahoo Finance, for the period from 2019-01-01 to 2023-12-31.

```{r}
tickers <- c("^SPX", "DELL", "EURUSD", "BZ=F", "ETH-USD")

date_from <- "2019-01-01"
date_to <- "2023-12-31"

download_data <- FALSE

if(download_data){
  for(ticker in tickers){
    if(ticker == "EURUSD") {
      next # downloaded from stooq instead, because of apparent incorrect dates in yahoo for EUR/USD
    }
    ticker_data <- getSymbols(Symbols = ticker,
             from = date_from,
             to = date_to,
             src="yahoo",
             auto.assign = FALSE)
    act_ticker <- gsub("^\\^", "", ticker)
    adj_ticker <- sprintf("%s.Adjusted", act_ticker)
    
    ticker_df <- data.frame(Date=index(ticker_data), Adjusted=ticker_data[, adj_ticker])
    names(ticker_df)[2] <- "Adjusted"

    write.csv(ticker_df, sprintf("./data/%s.csv", ticker), row.names=FALSE)
  }
}
```
```{r}
plot_quotes = function(df, quote_col, title){
  if(has_name(df, "Date"))
  {
      df_xts <- xts(df[, quote_col], order.by=df$Date)
  }
  else{
    df_xts <- xts(df[, quote_col], order.by=as.Date(rownames(df)))
  }
  plot(df_xts[,1],
     main = title,
     col = "red",
     major.ticks = "years", 
     grid.ticks.on = "years",
     grid.ticks.lty = 3,
     lwd = 2,
     cex = 0.5) 
}
```

## Quotes and Returns


```{r}
tickers_map = hash()
joined_returns = NULL

lr_label = function(ticker){
  return(sprintf("%s.r", ticker))
}


for(ticker in tickers){
  ticker_df <- read.csv(sprintf("./data/%s.csv", ticker), header=TRUE)
  ticker_df$Date <- as.Date(ticker_df$Date)
  
  r_label <- lr_label(ticker)
  
  ticker_df[[r_label]] <- diff.xts(log(ticker_df$Adjusted)) # log return
  
  tickers_map[[ticker]] <- ticker_df
  
  if(is.null(joined_returns)) {
    joined_returns <- ticker_df %>% select(Date, `r_label`)
  }
  else {
    joined_returns <- full_join(joined_returns, ticker_df %>% select(Date, `r_label`))
  }
  
}

joined_returns <- joined_returns %>% arrange(Date)
```
### S&P500

```{r}
plot_quotes(tickers_map[[tickers[1]]], "Adjusted", sprintf("%s Quotes", tickers[1]))
plot_quotes(tickers_map[[tickers[1]]], lr_label(tickers[1]), sprintf("%s differenced log returns", tickers[1]))
```

We observe huge volatility clustering around 2020 market crash and in 2022 during bearish market.

### Dell

```{r}
plot_quotes(tickers_map[[tickers[2]]], "Adjusted", sprintf("%s Quotes", tickers[2]))
plot_quotes(tickers_map[[tickers[2]]], lr_label(tickers[2]), sprintf("%s differenced log returns", tickers[2]))
```

Here the 2020 volatility cluster is more pronounced than of 2022.

### EUR/USD

```{r}
plot_quotes(tickers_map[[tickers[3]]], "Adjusted", sprintf("%s Quotes", tickers[3]))
plot_quotes(tickers_map[[tickers[3]]], lr_label(tickers[3]), sprintf("%s differenced log returns", tickers[3]))
```

For EUR/USD volatility cluster is visible for 2022.

### Brent

```{r}
plot_quotes(tickers_map[[tickers[4]]], "Adjusted", sprintf("%s Quotes", tickers[4]))
plot_quotes(tickers_map[[tickers[4]]], lr_label(tickers[4]), sprintf("%s differenced log returns", tickers[4]))
```

For Brent Crude Oil volatility clustering is observed in 2020 in 2022. 

### Ethereum

```{r}
plot_quotes(tickers_map[[tickers[5]]], "Adjusted", sprintf("%s Quotes", tickers[5]))
plot_quotes(tickers_map[[tickers[5]]], lr_label(tickers[5]), sprintf("%s differenced log returns", tickers[5]))
```

Not only does Ethereum have a volatility cluster around 2020 crash, but also it has volatility clustering in 2021, the era of meme stocks and coins. Obviously, it is even better visible on quotes chart.

## Portfolio

### Constructing Joint Log Returns

Here the important decision is whether to trade or not to trade on weekends and bank holidays. Since only Ethereum is traded all the time, we decide to trade only on working days. The alternative option is to replace all non-trading day returns with zeros, but this solution will reduce the overall variance of returns.

The list of non trading days was generated by ChatGPT-4o prompt "I need a list of weekend days and bank holidays for US since 2015 till 2025 in CSV file, column named Date, dates in format YYYY-mm-dd".

```{r}
non_trading_days <- read.csv("./data/non_trading_days.csv", header=TRUE)

joined_returns <- joined_returns %>% filter(! Date %in% non_trading_days$Date) %>% slice(-1)
print(sprintf("NAs left: %i", sum(is.na(joined_returns))))
```

The rest of the possible missing returns we are replacing with zeros.

```{r}
joined_returns <- joined_returns %>% replace(is.na(.), 0)
```

Now let's calculate the log-return of portfolio ($w_i=w=1/N$, $R$ stands for arithmetic return, $r$ - for logarithmic return).

$$
ln \dfrac{\Pi_{t+1}}{\Pi_{t}} = ln\dfrac{\sum_{i=1}^{N}S_{i,t+1}}{\Pi_t}=ln\dfrac{1/N\,\sum_{i=1}^{N}\Pi_{t}R_{i,t+1}}{\Pi_t} = ln \dfrac{1}{N}\sum_{i=1}^{N}R_{i,t+1} = ln \dfrac{1}{N}\sum_{i=1}^{N}e^{r_{i,t+1}}
$$

```{r}
ret_sum <- numeric(length(joined_returns))

for(ticker in tickers){
  ret_sum <- ret_sum + exp(joined_returns[, lr_label(ticker)])
}

joined_returns$r <- log(1/length(tickers) * ret_sum)
```

```{r}
head(joined_returns, n=10)
```
```{r}
tail(joined_returns, n=10)
```

### Plots of the log-returns.
```{r}
plot_quotes(joined_returns, "r", "Portfolio differenced log returns")
```

There is a clear volatility cluster at the beginning of 2020, as well as smaller clusters in the middle of 2021 and 2022.

### ACF plots for log returns and square log returns.

```{r}
plot_acf = function(values, max_lim, title){
  acf(values, lag.max = 36, na.action = na.pass,
    ylim = c(-0.2, max_lim), col = "darkblue", lwd = 4,
    main = title)
}
```

```{r}
plot_acf(joined_returns$r, 0.2, "ACF of portfolio log-returns")
plot_acf(joined_returns$r^2, 0.4, "ACF of portfolio squared log-returns")
```

Observations:

- There are a couple of lags for plain log-returns.
- On the other hand, there are significant ACF values for lags for squared log-returns, hence we can assume the presence of serial autocorrelation.

## Formal Testing for ARCH effects

### Heteroscedasticity of Residuals

```{r}
ArchTest(joined_returns$r, lags=10)
```
LM test strongly rejects null hypothesis of homoscedasticity of log-returns and no autocorrelation of squared log-returns.

```{r}
Box.test(resid(lm(joined_returns$r ~ 1)), type = "Ljung-Box", lag = 10)
```
```{r}
Box.test(resid(lm(joined_returns$r^2 ~ 1)), type = "Ljung-Box", lag = 10)
```

Ljung-Box test also strongly rejects the hypothesis of no autocorrelation both in simple and squared log-returns.

### Leptokurtosis

```{r}
jarque.bera.test(joined_returns$r)
```

Based on Jarque-Bera test and its very small p-value, we strongly reject hypothesis of log-returns following normal distribution.

```{r}
basicStats(joined_returns$r)
```

The distribution of log-returns is left-skewed and has high kurtosis.

```{r}
hist(joined_returns$r, prob = TRUE, breaks = 50)
curve(dnorm(x, mean = mean(joined_returns$r), sd  = sd(joined_returns$r)),
            col = "darkblue", lwd = 3, add = TRUE)
```

We see more pronounced left tail and high kurtosis.

The overall conclusion is that there are ARCH effects present in the log-returns of the portfolio.

# Modelling

```{r}
insample_r <- joined_returns %>% filter(Date < as.Date('2023-01-01'))
```

```{r}
fit_garch = function(returns, arma_p, arma_q, arch_q, garch_p, model_type = "sGARCH", submodel = NULL){

  if(!is.null(submodel) && model_type == "fGARCH"){
    variance_model = list(model = model_type,
                          submodel = submodel,
                          garchOrder = c(arch_q, garch_p))
  } else {
    variance_model = list(model = model_type,
                          garchOrder = c(arch_q, garch_p))
  }
  
  # Specify the GARCH model
  spec <- ugarchspec(
    variance.model = variance_model,
    mean.model = list(armaOrder = c(arma_p, arma_q), include.mean = TRUE),
    distribution.model = "norm")
  

  model <- ugarchfit(spec=spec, data=returns)
  return(model)
}

```

## Standard GARCH models

Let's begin with fitting some standard GARCH models.

### ARMA(0,0)-GARCH(1,1)

Let's begin with the simplest option of a constant mean equation and ARCH and GARCH orders of 1.
```{r}
plot_std_residuals = function(fit_model){
  plot(fit_model, which=10)
}
plot_std_sq_residuals = function(fit_model){
  plot(fit_model, which=11)
}
plot_conditional_sd = function(fit_model){
  plot(fit_model, which=3)
}
plot_news_impact_curve = function(fit_model) {
  plot(fit_model, which=12)
}
plot_r_std_density = function(fit_model){
  std_residuals = (fit_model@fit$residuals - mean(fit_model@fit$residuals)) / fit_model@fit$sigma

  hist(std_residuals, prob=TRUE, breaks=40)
  curve(dnorm(x, mean = mean(std_residuals), sd  = sd(std_residuals)),
            col = "darkblue", lwd = 3, add = TRUE)
}

```
```{r}
arma00garch11 <- fit_garch(insample_r$r, 0, 0, 1, 1)
arma00garch11
```

```{r}
plot_std_residuals(arma00garch11)
plot_std_sq_residuals(arma00garch11)
plot_conditional_sd(arma00garch11)
```

#### Comment

- All the estimates or parameters are significant. 
- ACF of standardized residuals shows almost no autocorrelation
- ACF of squared standardized residuals shows significant third lag.
- Both Ljung-Box test for standardized squared residuals and LM tests say that we reject null-hypothesis of no autocorrelation of said residuals, hence the model is not adequate.

### ARMA(0,0)-GARCH(2,1)

```{r}
arma00garch21 <- fit_garch(insample_r$r, 0, 0, 2, 1)
arma00garch21
```

```{r}
plot_std_residuals(arma00garch21)
plot_std_sq_residuals(arma00garch21)
plot_conditional_sd(arma00garch21)
```

#### Comment

- ARCH(1) and ARCH(2) parameters are insignificant. 
- ACF of standardized residuals shows almost no significant autocorrelation.
- ACF of squared standardized residuals shows significant third lag. It is smaller than in ARCH(0,0)-GARCH(1,1).
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals.


### ARMA(0,0)-GARCH(1,2)

```{r}
arma00garch12 <- fit_garch(insample_r$r, 0, 0, 1, 2)
arma00garch12
```
```{r}
plot_std_residuals(arma00garch12)
plot_std_sq_residuals(arma00garch12)
plot_conditional_sd(arma00garch12)
```

#### Comment

- GARCH(2) is not significant and estimated to be zero. 
- ACF of standardized residuals shows almost no autocorrelation.
- ACF of squared standardized residuals shows significant third lag.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals (except for LB 8th lag, but LM test shows no autocorrelation)


### ARMA(0,0)-GARCH(2,2)

```{r}
arma00garch22 <- fit_garch(insample_r$r, 0, 0, 2, 2)
arma00garch22
```
```{r}
plot_std_residuals(arma00garch22)
plot_std_sq_residuals(arma00garch22)
plot_conditional_sd(arma00garch22)
```

#### Comment

- ARCH(1), ARCH(2) and GARCH(2) parameters are not significant. GARCH(2) is close to zero. 
- ACF of standardized residuals shows almost no autocorrelation.
- ACF of squared standardized residuals shows significant third lag.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals.


### ARMA(0,0)-GARCH(3,3)

For the educational purposes let's investigate higher orders of GARCH, although we are aware that these models are considered complex and redundant in practice.

```{r}
arma00garch33 <- fit_garch(insample_r$r, 0, 0, 3, 3)
arma00garch33
```

```{r}
plot_std_residuals(arma00garch33)
plot_std_sq_residuals(arma00garch33)
plot_conditional_sd(arma00garch33)
```

#### Comment

- ARCH(1) and GARCH(2) parameters are not significant. GARCH(2) is even estimated to be zero. 
- ACF of standardized residuals shows almost no autocorrelation.
- ACF of squared standardized residuals shows significant third lag, but its magnitude is the lowest as of now.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals.

Perhaps, now we should move to altering mean equation to see the effects.

### ARMA(7,0)-GARCH(2,1)
```{r}
arma70garch21 <- fit_garch(insample_r$r, 7, 0, 2, 1)
arma70garch21
```

```{r}
plot_std_residuals(arma70garch21)
plot_std_sq_residuals(arma70garch21)
plot_conditional_sd(arma70garch21)
```

#### Comment

- All AR lags except for the 7th are insignificant. ARCH(2) is also insignificant.
- ACF of standardized residuals shows no autocorrelation.
- ACF of squared standardized residuals shows significant third lag, as in all previous cases.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals.


### ARMA(7,7)-GARCH(2,1)
```{r}
arma77garch21 <- fit_garch(insample_r$r, 7, 7, 2, 1)
arma77garch21
```
```{r}
plot_std_residuals(arma77garch21)
plot_std_sq_residuals(arma77garch21)
plot_conditional_sd(arma77garch21)
```

#### Comment

- AR(3), AR(4), MA(3), MA(4) lags are insignificant, as well as ARCH(2). 
- ACF of standardized residuals confidently shows no autocorrelation.
- ACF of squared standardized residuals shows significant third lag, as in all previous cases.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals.


Let's try reducing amount of ARMA lags.

### ARMA(5,5)-GARCH(2,1)
```{r}
arma55garch21 <- fit_garch(insample_r$r, 5, 5, 2, 1)
arma55garch21
```
```{r}
plot_std_residuals(arma55garch21)
plot_std_sq_residuals(arma55garch21)
plot_conditional_sd(arma55garch21)
```

#### Comment

- Only ARCH(2) is insignificant. 
- ACF of standardized residuals shows one significant lag.
- ACF of squared standardized residuals shows significant third lag, as in all previous cases.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals.

Let's try adding more GARCH components.

### ARMA(5,5)-GARCH(2,2)
```{r}
arma55garch22 <- fit_garch(insample_r$r, 5, 5, 2, 2)
arma55garch22
```
```{r}
plot_std_residuals(arma55garch22)
plot_std_sq_residuals(arma55garch22)
plot_conditional_sd(arma55garch22)
```

#### Comment

- ARCH(2), GARCH(2) are insignificant. 
- ACF of standardized residuals showed significant 9th lag.
- ACF of squared standardized residuals shows significant third lag and 14th.
- Both Ljung-Box test for standardized squared residuals and LM tests do not allow us to reject null-hypothesis of no autocorrelation of said residuals. Nevertheless, ACF plots are not great, and we can conclude that this model is not that good.


## EGARCH models

In this part, we will try other types of GARCH models, with various parameters. Let's begin with EGARCH.

### ARMA(0,0)-EGARCH(1,1)


```{r}
arma00egarch11 <- fit_garch(insample_r$r, 0, 0, 1, 1,model_type = "eGARCH")
arma00egarch11
```


```{r}
plot_std_residuals(arma00egarch11)
plot_std_sq_residuals(arma00egarch11)
plot_conditional_sd(arma00egarch11)
```
#### Comment

- Significant terms: omega, alpha1, beta1, gamma1

- The Ljung-Box tests for both residuals and squared residuals have high p-values, indicating no significant serial correlation or remaining ARCH effects, implying a well-fitted model

- The ARCH LM test shows some significant ARCH effects at lower lags, suggesting there may still be some unmodeled volatility clustering

- The model parameters indicate high persistence in conditional standard deviation (volatility), meaning that volatility shocks have a prolonged effect on future volatility.



### ARMA(0,0)-EGARCH(2,1)

```{r}
arma00egarch21 <- fit_garch(insample_r$r, 0, 0, 2, 1,model_type = "eGARCH")
arma00egarch21
```

```{r}
plot_std_residuals(arma00egarch21)
plot_std_sq_residuals(arma00egarch21)
plot_conditional_sd(arma00egarch21)
```
#### Comment

- The significant omega, alpha1, alpha2, and beta1 terms indicate the presence of volatility clustering and persistence in volatility

- The significant gamma1 term indicates the presence of asymmetry or leverage effects

- No significant serial autocorrelation was observed 

### ARMA(0,0)-EGARCH(1,2)

```{r}
arma00egarch12 <- fit_garch(insample_r$r, 0, 0, 1, 2, model_type = "eGARCH")
arma00egarch12
```

```{r}
plot_std_residuals(arma00egarch12)
plot_std_sq_residuals(arma00egarch12)
plot_conditional_sd(arma00egarch12)
```
#### Comment 

- The significant omega, alpha1, beta1, beta2, and gamma1 terms indicate the presence of volatility clustering and persistence in volatility

- Ljung-Box and LM tests suggest no significant autocorrelation between residuals


### ARMA(5,5)-EGARCH(2,1)

```{r}
arma55egarch21 <- fit_garch(insample_r$r, 5, 5, 2, 1, model_type = "eGARCH")
arma55egarch21
```

#### Comment

## TGARCH Models

### ARMA(0,0)-TGARCH(1,1)

```{r}
arma00tgarch11 <- fit_garch(insample_r$r, 0, 0, 1, 1, model_type = "fGARCH", submodel = "TGARCH")
arma00tgarch11
```

```{r}
plot_std_residuals(arma00tgarch11)
plot_std_sq_residuals(arma00tgarch11)
plot_conditional_sd(arma00tgarch11)
```
#### Comment 

- There are no signs of serial correlation in the residuals

- The model stability test indicates that the model is stable

- ARCH and GARCH components are highly significant

### ARMA(0,0)-TGARCH(1,2)

```{r}
arma00tgarch12 <- fit_garch(insample_r$r, 0, 0, 1, 2, model_type = "fGARCH", submodel = "TGARCH")
arma00tgarch12
```

```{r}
plot_std_residuals(arma00tgarch12)
plot_std_sq_residuals(arma00tgarch12)
plot_conditional_sd(arma00tgarch12)
```
#### Comment

- Omega, alpha1, beta2 and eta11 are significant

- No serial correlation in residuals but some evidence of remaining ARCH effects

### ARMA(0,0)-TGARCH(2,1)

```{r}
arma00tgarch21 <- fit_garch(insample_r$r, 0, 0, 2,1,model_type = "fGARCH", submodel = "TGARCH")
arma00tgarch21
```

```{r}
plot_std_residuals(arma00tgarch21)
plot_std_sq_residuals(arma00tgarch21)
plot_conditional_sd(arma00tgarch21)
```
#### Comment

- beta1 highly significant confirming volatility persistance

### ARMA(5,5)-TGARCH(2,1)
```{r}
arma55tgarch21 <- fit_garch(insample_r$r, 5, 5, 2, 1, model_type = "fGARCH", submodel = "TGARCH")
arma55tgarch21
```

```{r}
plot_std_residuals(arma55tgarch21)
plot_std_sq_residuals(arma55tgarch21)
plot_conditional_sd(arma55tgarch21)
```

#### Comment

### ARMA(5,5)-TGARCH(1,2)
```{r}
arma55tgarch12 <- fit_garch(insample_r$r, 5, 5, 1, 2,model_type = "fGARCH", submodel = "TGARCH")
arma55tgarch12
```

```{r}
plot_std_residuals(arma55tgarch12)
plot_std_sq_residuals(arma55tgarch12)
plot_conditional_sd(arma55tgarch12)
```
#### Comment

### Model Selection

Since for most models LM and LB tests have not been able to reject null-hypothesis of no standardized simple/squared residuals autocorrelation, and the 3rd ACF lag for standardized squared residuals has not been removed fully by most of the models as well, we decide to choose among models which are the simplest and/or have the largest number of significant coefficient estimations.

These models are ARMA(0,0)-GARCH(2,1) and ARMA(5,5)-GARCH(2,1) and ARMA(7,7)-GARCH(2,2).

For other GARCH models we select ARMA(0,0)-EGARCH(2,1), ARMA(5,5)-EGARCH(2,1) and ARMA(5,5)-TGARCH(2,1)
```{r}

compare_ICs_GARCH <- function(models_list) { 
  n <- length(models_list)
  
  for(i in 1:n) {
    ICs_ <- data.frame(t(infocriteria(models_list[[i]])))
    if(i == 1) ICs <- ICs_ else ICs <- rbind(ICs, ICs_)
  }
  
  mins <- sapply(ICs[,1:(ncol(ICs)-1)], function(x) which(x == min(x)))
  
  return(list(ICs = ICs, which.min = mins))
}

candidate_models_list <- c(arma00garch21, arma55garch21, arma77garch21, arma00egarch21, arma55egarch21, arma55tgarch21)

ic_compare <- compare_ICs_GARCH(candidate_models_list)
ic_compare
```

Based on information criteria comparison, ARMA(5,5)-EGARCH(2,1) is the best for all criteria except BIC, where ARMA(0,0)-GARCH(2,1) is the best. Let's then choose these two models as final ones.

```{r}
chosen_garch = function(returns){
  return(fit_garch(returns, 0, 0, 2, 1))
}
```

```{r}
chosen_mod_garch = function(returns){
  return(fit_garch(returns, 5, 5, 2, 1, model_type = "eGARCH"))
}
```

# Futher Diagnostics

## ARMA(0,0)-GARCH(2,1)

```{r}
arma00garch21
```

#### Parameters 

As mentioned previously, ARCH(1) and ARCH(2) are insignificant.

Mu is an estimated mean of log-returns. It is close to zero, which is expected for log-returns.
Omega is an intercept of conditional variance equation. It is positive and very close to zero.
ARCH parameters are positive but small, indicating that lagged shocks somewhat influence the current conditional variance
GARCH(1) of 0.82 shows strong influence of lagged conditional variance.

#### Nyblom Stability test

Regarding Nyblom stability test, we see that the joint stability statistic is large, 6.3395 > 1.47 at 5% confidence level. Hence we reject null hypothesis of joint parameter stability. Nevertheless, all individual statistics are smaller than 0.47, hence we cannot reject the null of individual parameter stability.

#### Sign bias test

Negative Sign Bias test rejects the null of no asymmetry. It means that the model reacts strongly on negative returns. The joint effect of biases is also significant.

#### Goodness-of-fit test
All p-values are small, suggesting that the model does not fit the data well in any grouping.

#### News impact curve

```{r}
plot_news_impact_curve(arma00garch21)
```

The curve shows that lagged shock value impacts current conditional variance equally. For returns we would like to see stronger volatility reaction on negative shocks.

### Standardized residuals

```{r}
plot_r_std_density(arma00garch21)
```

```{r}
std_residuals = (arma00garch21@fit$residuals 
                 - mean(arma00garch21@fit$residuals)) / arma00garch21@fit$sigma

print(basicStats(std_residuals))
```

```{r}
print(jarque.bera.test(std_residuals))
```

The distribution of standardized residuals is platykurtic.


## ARMA(5,5)-EGARCH(2,1)

Let's display the statistics of the model again.

```{r}
arma55egarch21
```

### Parameters Discussion

- Each parameter is significant (even highly significant).
- alpha values indicate presence of lagged error terms influence, albeit a mild one, because absolute values are somewhat small.
- On the contrary, beta is very large, indicating strong influence of lagged volatility.
- Regarding the asymmetry of reaction, according to the rugarch specification, the sign effect is captured by alpha. The alpha1 is negative and larger in absolute value than alpha2, therefore we conclude that negative shocks will have more impact on volatility than positive, at least for the first lag.
- gamma values are positive. According to the rugarch specification, it indicates the influence of difference $|z_t|-E|z_t|$ (absolute standardized residuals), so it seems in this context it is desired for gamma to be positive (as opposed to the gamma from lecture 10).

### Nyblom stability test

Joint Statistic is 2.1538 (Critical Value at 5%: 3.95) and all individual statistics are below their respective critical values, indicating parameter stability.

### Ljung - Box and LM tests

No autocorrelation between residuals.

### Goodness-of-Fit Test

The goodness-of-fit test indicates bad fit quality: we reject the null.

### Sign Bias Test

The test fails to reject the null of no bias, and we have achieved the symmetry in reaction to both negative and positive shocks, which is good. 

### News Impact Curve

```{r}
plot_news_impact_curve(arma55egarch21)
```

As expected from the eGARCH model, negative shocks produce more influence on volatility than positive. This is the desired outcome for returns.

### Standardized residuals

```{r}
plot_r_std_density(arma55egarch21)
```
```{r}
std_residuals = (arma55egarch21@fit$residuals 
                 - mean(arma55egarch21@fit$residuals)) / arma55egarch21@fit$sigma

print(basicStats(std_residuals))
print(jarque.bera.test(std_residuals))
```

The distribution of standardized residuals is platykurtic.

# Value-at-Risk

```{r}
plot_var = function(dates, returns, vars, ylims){
  if(missing(ylims))
  {
    ylims = c(-0.2, 0.1)
  }
  
  plot(dates, returns, 
   col = "red", lwd = 1, type = 'l', 
   ylim = ylims)
  abline(h = 0, lty = 2)
  lines(dates, vars, type = 'l', col = "green")
}

var_losses = function(returns, vars){
  sum(returns < vars) / length(vars)
}
```



Value-at-Risk is assumed at confidence level 1%. The empirical quantile is:

```{r}
get_var_quantile = function(returns, q_value) {
  rstd <- (returns - mean(returns))/sd(returns)
  q <-  quantile(rstd, q_value)
  return(q)
}

threshold = 0.01
var_q <- get_var_quantile(insample_r$r, threshold)
var_q
```

## In-sample

### GARCH

Calculate VAR from chosen model.

```{r}
insample_garch <- chosen_garch(insample_r$r)
vars <- var_q * insample_garch@fit$sigma
```
```{r}
plot_var(insample_r$Date, insample_r$r, vars)
```


```{r}
var_losses(insample_r$r, vars)
```
Worse than expected. Let's test with VaR 5%.

```{r}
vars <- get_var_quantile(insample_r$r, 0.05) * insample_garch@fit$sigma
plot_var(insample_r$Date, insample_r$r, vars)
var_losses(insample_r$r, vars)
```

VaR 5% breaches are in expected range.

### EGARCH
```{r}
insample_egarch <- chosen_mod_garch(insample_r$r)
vars <- var_q * insample_egarch@fit$sigma
```

```{r}
plot_var(insample_r$Date, insample_r$r, vars)
```
```{r}
var_losses(insample_r$r, vars)
```

```{r}
vars <- get_var_quantile(insample_r$r, 0.05) * insample_egarch@fit$sigma
plot_var(insample_r$Date, insample_r$r, vars)
```
```{r}
var_losses(insample_r$r, vars)
```


## Out-of-sample

```{r function}
joined_returns$obs <- 1:length(joined_returns$r)
outofsample_r <- joined_returns %>% filter(Date >= as.Date('2023-01-01'))

start <- (joined_returns %>% 
            filter(Date >= as.Date("2023-01-01")) %>% 
            filter(row_number() == 1))$obs
finish  <- (joined_returns %>% filter(row_number() == n()))$obs

forecast_rolling_var = function(q_value, garch_func) {
  vars <- rep(NA, times = finish - start + 1)
  
  n_cores = detectCores() - 1
  cluster <- makeCluster(n_cores)
  registerDoParallel(cluster)
  
  vars <- foreach(new_idx=start:finish,
                  .export=c("joined_returns", "get_var_quantile", "fit_garch", 
                            "ugarchspec", "ugarchfit", "ugarchforecast")) %dopar% {
     rolling_data <- joined_returns[joined_returns$obs <= new_idx-1, ]
     q <- get_var_quantile(rolling_data$r, q_value)

     rolling_garch <- garch_func(rolling_data$r)
     forecast <- ugarchforecast(rolling_garch, n.ahead = 1)
     sigma_for <- forecast@forecast$sigmaFor[1, 1]
     
     q * sigma_for
  }
  
  stopCluster(cluster)
  
  return(vars)
}

```


### GARCH

```{r}
vars_garch <- forecast_rolling_var(0.01, chosen_garch)
```

```{r}
plot_var(outofsample_r$Date, outofsample_r$r, vars_garch, ylims=c(-0.05, 0.05))
var_losses(outofsample_r$r, vars_garch)
```

There are no return values breaching VaR 1%.

### EGARCH

```{r}
vars_egarch <- forecast_rolling_var(0.01, chosen_mod_garch)
```

```{r}
plot_var(outofsample_r$Date, outofsample_r$r, vars_egarch, ylims=c(-0.05, 0.05))
var_losses(outofsample_r$r, vars_egarch)
```

There are no return values breaching VaR 1%.
